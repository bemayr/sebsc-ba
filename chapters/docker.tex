% --- Books ---
% - https://www.amazon.de/Docker-Software-entwickeln-deployen-Containern/dp/386490384X/ref=sr_1_1?ie=UTF8&qid=1483784437&sr=8-1&keywords=docker
% - https://www.amazon.com/Docker-Action-Jeff-Nickoloff/dp/1633430235/ref=sr_1_1?ie=UTF8&qid=1483784469&sr=8-1&keywords=docker
% - https://www.amazon.com/Docker-Practice-Ian-Miell/dp/1617292729/ref=sr_1_10?ie=UTF8&qid=1483784469&sr=8-10&keywords=docker
% - https://www.amazon.com/Developing-Docker-Jaroslaw-Krochmalski-ebook/dp/B01GEJKJ6A/ref=sr_1_33?ie=UTF8&qid=1483784510&sr=8-33&keywords=docker

\chapter{Docker}
\label{cha:docker}
Wie in \cref{sec:vollvirtualisierung} beschrieben, ermöglicht die Virtualisierung von IT-Systemen eine Abstraktion der Hardware.
Ressourcen lassen sich effizienter nutzen, die Systeme werden jedoch nicht optimal ausgenützt, da das gesamte Betriebssystem virtualisiert wird.
Dies führt zu langen Startzeiten und einem hohen Speicherverbrauch.

Containervirtualisierung (siehe \cref{sec:containervirtualisierung}) löst diese Probleme durch die Wiederverwendung des Kernels.
Dadurch entsteht die Möglichkeit, Anwendungen mitsamt den benötigten Systemressourcen zu verpacken und die Abhängigkeiten für den Betrieb zu reduzieren.
Für einen Container wird lediglich die Laufzeitumgebung benötigt. Ist diese installiert, ist garantiert, dass der Container funktioniert.
Docker\footnote{\url{https://www.docker.com/}} wird in 94\% (Stand Juni 2016) der Unternehmen eingesetzt, die auf Containervirtualisierung setzen \autocite{ContainerAdoption}.

\section{Geschichte}
\label{sec:docker-history}
Der Blogeintrag \autocite{redhat-container-history:online} schildert die Geschichte der Containervirtualisierung. Folgende Darstellung ist eine Zusammenfassung dieses Eintrags.

Im Jahr 2001 ermöglicht Jacques Gélinas mithilfe eines gepatchten Kernels zum ersten Mal das Ausführen mehrerer Linux-Server auf einem einzelnen Rechner, ohne auf Vollvirtualisierung zurückzugreifen.

2006 folgt die Aufnahme von cgroups in den Linux-Kernel, worauf 2008 die Implementierung der namespaces folgt.
Ebenfalls 2008 beginnt IBM mit der Entwicklung von LXC, wobei auf cgroups und namespaces aufgesetzt wird.
% http://searchservervirtualization.techtarget.com/feature/A-brief-history-of-Docker-Containers-overnight-success
% http://blog.aquasec.com/a-brief-history-of-containers-from-1970s-chroot-to-docker-2016

2013 wird Docker als Open-Source-Projekt der Platform-as-a-Service-Umgebung dotCloud vorgestellt.
Docker führt nichts wesentlich Neues ein, sondern bietet lediglich für die bestehenden Technologien wie LXC eine sehr einfach zu verwendende Benutzerschnittstelle, die Container für eine breite Benutzergruppe zugänglich macht.

2014 erscheint Docker in der Version 1.0, nachdem mit Version 0.9 LXC als Containerumgebung durch \emph{libcontainer\footnote{\url{https://github.com/opencontainers/runc/tree/master/libcontainer}}} ersetzt wird.
libcontainer ist eine Eigenentwicklung von Docker, die in der Programmiersprache Go geschrieben ist und die Verwaltung und Ausführung von Containern ermöglicht.

2015 tritt Docker der Open Container Initiative bei, wodurch die Quelltexte und Entwicklungen dem unter der Linux Foundation stehenden Projekt hinzugefügt werden.
Dieser Schritt verstummt Kritiker, die eine Monopolstellung von Docker befürchtet haben.
Seit 2015 werden hauptsächlich Fehlerbehebungen und Verbesserungen an Docker selbst durchgeführt sowie das Docker-Ökosystem durch zahlreiche Werkzeuge erweitert (siehe \cref{sec:docker-products}).

Die in diesem Kapitel gezeigten Beispiele und verwendeten Funktionen basieren auf der Docker-Version 1.13 vom 19. Jänner 2017.
\section{Funktionsweise}
\label{sec:docker-basics}
Die Funktionsweise von Docker ist in \autocite{docker-overview:online} beschrieben und wird im folgenden Abschnitt zusammengefasst.
Docker basiert auf einer Vielzahl von Komponenten, die erst als Gesamtsystem eine Containervirtualisierung ermöglichen.
Ein grundlegendes Wissen über diese Komponenten ist für die Verwendung von Docker unerlässlich.
Folgende Komponenten sind essenziell:
\begin{description}
    \item [daemon] Im Hintergrund von Docker läuft der Server-Prozess, genannt \texttt{daemon}, der sich um das Anlegen und Verwalten von \texttt{images}, \texttt{container}, \texttt{networks} und \texttt{data volumes} kümmert.
    Er läuft auf dem Host-System und nimmt Kommandos der \texttt{clients} über eine REST-Schnittstelle entgegen.
    \item [client] Der \texttt{client} ist die Benutzeroberfläche von Docker, die in Form einer Kommandozeilenanwendung zur Verfügung steht.
    Er nimmt Kommandos und Konfigurationen entgegen und sendet diese an einen zuvor festgelegten \texttt{daemon}.
    \item [engine] Als \texttt{engine} wird die Kombination aus \texttt{daemon} und \texttt{client} bezeichnet, die den Kern von Docker bildet.
    \item [image] Ein \texttt{image} ist eine Vorlage für das Erstellen eines \texttt{containers}. \texttt{Images} können erweitert und dadurch wiederverwendet werden. Sie bilden die Basis zum Erstellen eines \texttt{containers}. Images sollten immer deklarativ mithilfe von Dockerfiles (siehe \cref{sec:dockerfiles}) erstellt werden.
    \item [container] \texttt{container} sind jene Teile, die von Docker ausgeführt werden. Sie sind die ausführbare Instanz eines \texttt{images}. \texttt{container} werden vom \texttt{daemon} gestartet, gestoppt, verschoben oder gelöscht, der die Anweisungen vom \texttt{client} enthält. Zusätzlich können \texttt{container} zur Inter-Container-Kommunikation Netzwerken zugewiesen oder zur Datenpersistierung mit Speicherbereichen versorgt werden.
    \item [registry] \texttt{registries} dienen der Verteilung von \texttt{images}. Sie stellen eine Bibliothek dieser dar und können entweder privat oder öffentlich zugänglich sein (siehe \cref{sec:docker-hub}).
    \item [service] Ein \texttt{service} ist eine Sammlung von Docker-Containern, welche durch einen Schwarmmanger (siehe \cref{sec:docker-swarm}) verwaltet wird und die Basis für Multi-Container-Anwendungen darstellt. Seit Docker 1.12 werden \texttt{services} in vollem Ausmaß unterstützt.
\end{description}
In \cref{lst:docker-run-basics} wird ein neuer Container auf Basis des Ubuntu-Images gestartet, in dem sodann die Bash gestartet wird.
\begin{lstlisting}[caption=Ubuntu-Bash in Docker, language=bash, label=lst:docker-run-basics]
    $ docker run -i -t ubuntu /bin/bash
\end{lstlisting}
Dabei erledigt die Docker-Engine folgende Schritte:
\begin{enumerate}
    \item Das \texttt{ubuntu}-Docker-Image wird von der Docker-Registry heruntergeladen, falls dieses lokal noch nicht existiert.
    \item Ein neuer Container wird auf Basis des Images erstellt und mit einem zufälligen Namen versehen.
    \item Ein schreibfähiges Dateisystem wird zu dem eben erstellten Container hinzugefügt.
    \item Für den Container wird eine Netzwerkverbindung geschaffen, die eine Kommunikation mit dem Host ermöglicht. Standardmäßig wird die \texttt{bridged}-Schnittstelle verwendet.
    \item Der Container erhält eine IP-Adresse.
    \item Das angegebene Programm wird ausgeführt. In diesem Fall ist das \texttt{/bin/bash}.
    \item Die Parameter \texttt{-t} und \texttt{-i} führen dazu, dass die Standardeingabe und Standardausgabe verbunden werden und der Container in einen interaktiven Modus geschaltet wird. Der Benutzer befindet sich nun in der Bash in Ubuntu in Docker.
\end{enumerate}
In \cref{fig:docker-architektur} ist dieser Ablauf grafisch dargestellt.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.75\linewidth,clip,trim=70 100 70 80]{images/docker-architecture}
    \caption{Docker-Architektur}
\label{fig:docker-architektur}
\end{figure}


\section{Plattformen}
\label{sec:docker-platforms}
Docker läuft nur auf Linux-Versionen nativ, deren Kernels zu Docker kompatibel sind.
Auf allen anderen Systemen wird durch virtualisierte Umgebungen eine Möglichkeit geschaffen Docker auszuführen.
Bei diesen Werkzeugen wurde im letzten Jahr viel geändert, wodurch die Verwendung von Docker unter Windows und macOS stark vereinfacht wurde, derzeit allerdings eine Vielzahl von Werkzeugen existiert. Nachfolgend wird ein kurzer Überblick gegeben.

\subsection{Docker for Windows}
\label{sec:docker-windows}
Docker for Windows verwendet Hyper-V für die Erstellung einer virtuellen Linux-Maschine zur Ausführung von Docker \autocite{docker-for-windows:online}.
Zusätzlich werden die Docker-Client-Anwendungen installiert.
Nicht zu verwechseln ist Docker for Windows mit den Windows-Containern\footnote{\url{https://docs.microsoft.com/en-us/virtualization/windowscontainers/about/}}, die sich noch in der Beta-Phase befinden.
Zur Verwendung dieser gibt es auf der offiziellen Docker-Homepage eine Anleitung\footnote{\url{https://docs.docker.com/docker-for-windows/install/}}.
Ein sehr nützliches Add-on für die Verwendung von Docker unter Windows ist \texttt{posh-docker}\footnote{\url{https://github.com/samneirinck/posh-docker}}, welches die automatische Vervollständigung der Docker-Kommandos auf der Powershell ermöglicht.
Vor allem durch die Integration des Port-Forwarding und der Möglichkeit, auch in Docker auf das gesamte Dateisystem zuzugreifen, fühlt sich die Verwendung von Docker for Windows beinahe nativ an.

\subsection{Docker for Mac}
\label{sec:docker-mac}
Docker for Mac ist das Pendant zu Docker for Windows.
Es nutzt die Virtualisierungslösung HyperKit, welche seit macOS 10.10 Yosemite nativ verfügbar ist \autocite{docker-for-mac:online}.
Ebenso wie in der Windows-Version bietet die Mac-Version eine grafische Benutzeroberfläche zur Verwaltung der Anwendung.

\subsection{Docker Toolbox}
\label{sec:docker-toolbox}
Die Docker Toolbox war die erste offizielle Möglichkeit Docker auf Windows oder macOS laufen zu lassen \autocite{docker-toolbox:online}.
Sie wird von Docker \emph{nicht} mehr empfohlen, da es mit den nativen Lösungen nun zu wesentlich weniger Problemen und einem geringeren Overhead kommt.
Docker Toolbox installiert die Docker-Client-Werkzeuge sowie Oracle VM VirtualBox.
Darin wird eine virtuelle Maschine "`boot2docker"' angelegt, auf der der Docker-Daemon läuft.
Zusätzlich wird eine vorkonfigurierte git-Bash angeboten, die sich automatisch zu diesem Docker-Host verbindet.

Der Hypervisor für die virtuelle Maschine lässt sich mit etwas Mühe austauschen\footnote{\url{https://github.com/pecigonzalo/docker-machine-vmwareworkstation}}, was aber zu zahlreichen Problemen führt.
Wenn Docker for Windows und eine Virtualisierungslösung wie VMware oder VirtualBox gleichzeitig verwendet werden sollen, ergibt sich ein Konflikt zwischen den Hypervisoren und Hyper-V.
Aufgrund von Problemen wie der fehlenden Möglichkeit, Dateien zwischen dem Host und Docker zu teilen, sollte allerdings anstatt der Docker Toolbox die Lösung von Scott Hanselman \autocite{hanselman-vms:online} in Betracht gezogen werden.
Er erklärt darin eine Möglichkeit, mehrere Hypervisoren und Hyper-V parallel zu verwenden.
Dies ist allerdings nur durch einen Neustart des Systems möglich.
Diese Lösung ist zwar etwas umständlich, bietet aber die aktuellsten Versionen und die geringsten Einbußen.
Derzeit (Februar 2017) gibt es keine bessere Lösung.

% - die Geschichte von Docker
% - Docker Aufbau, LXC, usw...
% - https://youtu.be/9CuClvKMt04?t=1m12s
% - Plattformunterschiede, Docker-Toolbox, Native-Docker, mein Docker Setup
% - Docker Windows 10
%   - http://stackoverflow.com/questions/41338203/import-module-posh-docker-is-not-working
%   - https://github.com/samneirinck/posh-docker
%   - http://stackoverflow.com/questions/39133098/how-to-mount-a-windowss-folder-in-docker-using-powershell-or-cmd
%   - http://superuser.com/questions/1051520/docker-windows-container-how-to-mount-a-host-folder-as-data-volume-on-windows
%   - https://github.com/docker/for-win/issues/328
%   - https://rominirani.com/docker-on-windows-mounting-host-directories-d96f3f056a2c
% - Clean up: https://lebkowski.name/docker-volumes/

\section{Produkte}
\label{sec:docker-products}
Das Docker-Ökosystem besteht mittlerweile aus zahlreichen Komponenten, wobei die Docker-Engine um zusätzliche Werkzeuge erweitert wird.
Die folgenden Informationen stammen aus \autocite{docker-engine:online}.
\subsubsection{Docker Hub}
\label{sec:docker-hub}
Der \emph{Docker Hub} ist die offizielle Registry für Docker-Images. Dort werden offizielle Images wie Ubuntu, MySQL, Redis und zahlreiche weitere angeboten.
Zusätzlich können im Docker Hub eigene Images hochgeladen werden, für die auch die Möglichkeit des automatischen Erstellens bei Änderungen in Github angeboten wird.
Der Docker Hub ist auch eine exzellente Quelle zum Lernen von Best-Practices.
Zu den meisten Images existieren Dockerfiles, die gelesen, studiert und nachgebaut werden können.
\subsubsection{Docker Machine}
\label{sec:docker-machine}
\emph{Docker Machine} ist das Werkzeug zum Verwalten von Docker-Hosts.
Dieses Kommandozeilenwerkzeug ermöglicht das Erstellen und Verwalten von virtuellen Hosts, auf denen Docker bereits konfiguriert und einsatzbereit ist.
Docker Machine kann sowohl für die Konfiguration des Entwicklungsrechners verwendet werden als auch für die Provisionierung von Docker-Hosts in der Cloud oder in Datenzentren.
\subsubsection{Docker Compose}
\label{sec:docker-compose}
\emph{Docker Compose} bietet die Grundlage für komplexe Anwendungen.
Diese lassen sich nicht in einen Container verpacken, da sie aus zahlreichen Services bestehen.
Mithilfe eines eigenen auf YAML basierenden Dateiformates lassen sich diese Services deklarativ beschreiben und mithilfe von \texttt{docker-compose} ausführen und zentral verwalten.
\subsubsection{Docker Swarm}
\label{sec:docker-swarm}
\emph{Docker Swarm} ist die offizielle Lösung zum Betrieb von Docker in lastintensiven, kritischen und hochverfügbaren Umgebungen.
Mithilfe von Docker Swarm lassen sich mehrere Hosts zu einem virtuellen Host zusammenfassen, der in Folge die Docker-Kommandos ausführt.
Da die API ident ist, müssen keine Anpassungen durchgeführt werden, wodurch bestehende Docker-Kommandos weiterverwendet werden können.
Allerdings bietet Docker Swarm eine wesentlich höhere Leistung und Ausfallsicherheit.


\section{Dateisystem}
\label{sec:dateisystem}
Bevor im nächsten Kapitel das Erstellen von Containern mithilfe von Dockerfiles beschrieben wird, ist es wichtig, die Konzepte rund um das von Docker verwendete Dateisystem zu verstehen.
Diese werden nachfolgend vorgestellt; sie sind aus \autocite{docker-filesystem:online} entnommen.
In \cref{fig:docker-dateisystem} ist dargestellt, wie das Dateisystem von Docker arbeitet.

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.7\linewidth,clip,trim=130 130 130 110]{images/docker-filesystem}
    \caption{Docker-Dateisystem}
\label{fig:docker-dateisystem}
\end{figure}

Jedes Image besteht aus mehreren gestapelten Schichten.
Die einzelnen Schichten merken dies allerdings nicht.
Jede dieser Schichten bekommt eine kombinierte Sicht auf alle darunterliegenden.
Sie kann selbst Dateien hinzufügen, ändern oder als gelöscht markieren, ändert allerdings die darunterliegenden Schichten nicht.
Dieses Dateisystem-Konzept wird Union File System genannt.

Dadurch wird Docker sehr speichereffizient, da idente Schichten nur einmal existieren.
Ein Image, das auf einem anderen aufbaut, teilt sich dieselbe Basisschicht, welche, durch einen eindeutigen Hash identifiziert, wiederverwendet werden kann.
Dadurch wird auch beim Start von zahlreichen gleichen Containern beinahe kein Speicherplatz benötigt, denn die schreibgeschützte Image-Schicht wird von jedem Container wiederverwendet.


\section{Dockerfiles}
\label{sec:dockerfiles}
Zum Erstellen von Images gibt es in Docker zwei Ansätze.
Die erste Möglichkeit besteht darin, ein Basis-Image mit einer Shell zu starten und in dieser die benötigten Kommandos und Änderungen auszuführen.
Nach allen ausgeführten Kommandos wird der Zustand dieses Containers eingefroren und in ein Image verwandelt.
Dies führt allerdings dazu, dass dieser Prozess nur sehr schwer reproduzierbar ist.
Aus diesem Grund gibt es die sogenannten \emph{Dockerfiles}.
Sie stellen Bauanleitungen für ein Docker-Image dar, die an den Docker-Deamon übergeben werden, der auf Basis dieser das Image erstellt.
Daraus resultiert ein reproduzierbarer und plattformunabhängiger Erstellungsprozess.

\lstinputlisting[caption=Apache-Dockerfile von kstaken,label={lst:dockerfile-apache}]{listings/Dockerfile.apache}
In \cref{lst:dockerfile-apache} wird ein Apache-Webserver auf einem Ubuntu-Linux aufgesetzt und für den Einsatz vorbereitet.
Dieser Dockerfile\footnote{\url{https://github.com/kstaken/dockerfile-examples/blob/master/apache/Dockerfile}} wird von Kimbro Staken als quelltextoffenes Beispiel geführt und beinhaltet einige der wichtigsten Dockerfile-Instruktionen.
Nachfolgend werden die verwendeten Instruktionen beschrieben, eine vollständige Übersicht bietet \autocite{docker-dockerfile:online}.
\begin{description}
    \item[FROM] Die \emph{FROM}-Anweisung spezifiziert das Basis-Image des Containers. Auf dieser Schicht wird der Container aufgebaut. Meistens wird dies ein offizielles Image des Docker-Hubs sein, das weiter parametrisiert und konfiguriert wird.
    \item[LABEL] Die \emph{LABEL}-Anweisung ersetzt ältere Anweisungen wie zum Beispiel \emph{Maintainer}. Sie bietet die Möglichkeit Schlüssel-Wert-Paare zu einem Image zu speichern.
    \item[RUN] \emph{RUN} ermöglicht das Ausführen von Befehlen zum Erstellen des Images. Jedes RUN erzeugt eine neue Schicht des Images. In diesem Fall wird RUN verwendet um mit dem Paketmanager \texttt{apt-get} Apache zu installieren und gleich im Anschluss das System wieder aufzuräumen.
    \item[ENV] Mit dem \emph{ENV}-Befehl werden Umgebungsvariablen gesetzt.
    \item[EXPOSE] \emph{EXPOSE} kennzeichnet die Netzwerk-Ports, auf denen der Container zur Laufzeit erreichbar ist. Die Ports werden lediglich als verfügbar gekennzeichnet. Ob und auf welchem Port der Container tatsächlich erreichbar ist, bestimmt der Anwender beim Starten des Containers.
    \item[CMD] \emph{CMD} spezifiziert jene Anwendung, die standardmäßig beim Starten des Containers ausgeführt wird. Diese kann beim Starten des Containers überschrieben werden. Genauere Informationen dazu sind unter \cref{sec:cmd-vs-entrypoint} zu lesen.
\end{description}

Um aus diesem Dockerfile ein Image zu erstellen muss ein \texttt{docker build} ausgeführt werden.
Dieses Kommando könnte beispielsweise wie in \cref{lst:dockerfile-build} aussehen.

\begin{lstlisting}[caption=Ubuntu-Bash in Docker, language=bash, label=lst:dockerfile-build]
    $ docker build -t kstaken/apache .
\end{lstlisting}
Der Parameter \texttt{-t} weist dem erstellten Image den Namen \texttt{kstaken/apache} zu.
Dieser kann dann verwendet werden um einen Container auf Basis dieses Image zu starten.
Der Punkt am Ende des Kommandos spezifiziert den Build-Kontext.
Alle Dateien in diesem Pfad sind während des Docker-Builds verfügbar und können dem Image hinzugefügt werden.
Standardmäßig sucht Docker nach einer Datei namens \texttt{Dockerfile} in dem angegebenen Kontext.
Dies kann mit dem Parameter \texttt{-f} überschrieben werden.

\subsection{Best Practices}
\label{sec:dockerfile-best-practices}
Für das Erstellen von Dockerfiles werden von Docker folgende Best-Practices vorgeschlagen \autocite{docker-dockerfile-best-practices:online}:
\begin{itemize}
    \item Container sollen per Definition "`flüchtig"' gestaltet werden. Damit ist gemeint, dass ein Container mit minimalem Aufwand gestoppt, gelöscht und neu gestartet werden kann. Der Container muss von seinem Zustand unabhängig sein. Dies bedeutet, dass Daten und Konfigurationen außerhalb des Containers existieren müssen.
    \item Ein Container soll so klein wie möglich sein (siehe \cref{sec:minimize-imagesize}). Unnötige Pakete sollen vermieden werden. Ein Datenbankcontainer benötigt keinen Texteditor.
    \item Jeder Container soll im Gesamtsystem lediglich \emph{eine} Aufgabe haben. Durch diese Aufteilung können Systeme wesentlich besser skalieren. Diese Regel besagt nicht, dass ein Container lediglich einen Prozess ausführen darf. Prozesse können auch Kindprozesse starten, allerdings soll damit nur eine Aufgabe gelöst werden.
    \item Die Anzahl der Schichten eines Images soll möglichst gering gehalten werden. Alles in einen Befehl zu packen ist allerdings auch nicht der richtige Weg. Hier muss ein guter Mittelweg gefunden werden. Die offiziellen Images im Docker Hub bieten dafür sehr gute Lernressourcen.
    \item Mehrzeilige Argumente sollen zur besseren Wartbarkeit alphabetisch sortiert werden.
    \item Durch die Wiederverwendung von Schichten bietet Docker die Möglichkeit eines Build-Caches. Unveränderte Teile des Images müssen nicht neu erzeugt werden. Daher sollen die Schichten so gestaltet werden, dass sich häufig ändernde Module möglichst spät hinzugefügt werden, da dies die Geschwindigkeit beim Erzeugen eines Images erheblich beschleunigt.
\end{itemize}

\subsubsection{Reduktion der Imagegröße}
\label{sec:minimize-imagesize}
\subsubsection{CMD vs. ENTRYPOINT}
\label{sec:cmd-vs-entrypoint}

% - Layers
% - ...
% - http://bitjudo.com/blog/2014/03/13/building-efficient-dockerfiles-node-dot-js/
% - Example: https://nodejs.org/en/docs/guides/nodejs-docker-webapp/ (http://jdlm.info/articles/2016/03/06/lessons-building-node-app-docker.html)
% - https://www.brandpending.com/2016/06/14/building-nodejs-with-npm-dependencies-into-a-docker-container-without-using-a-dockerfile/ ???
% - Faster Builds: http://thenewstack.io/understanding-the-docker-cache-for-faster-builds/
% - Building good Images
% - https://blog.replicated.com/2016/02/05/refactoring-a-dockerfile-for-image-size/
% - https://nickjanetakis.com/blog/alpine-based-docker-images-make-a-difference-in-real-world-apps
% - http://blog.xebia.com/create-the-smallest-possible-docker-container/

% - ENTRYPOINT vs. CMD
% - https://www.ctl.io/developers/blog/post/dockerfile-entrypoint-vs-cmd/
% - http://goinbigdata.com/docker-run-vs-cmd-vs-entrypoint/
% - http://www.projectatomic.io/docs/docker-image-author-guidance/
% \section{Multi-Container-Anwendungen} % - Namen überdenken!!!
% \label{sec:docker-multi-container-anwendungen}
% - fig vs. docker-compose
% - Bash-Skripte vs. docker-compose
% - bei größeren Systemen auf Kapitel 1 (Orchestration) verweisen
% - https://ypereirareis.github.io/blog/2015/05/04/docker-with-shell-script-or-makefile/
% - http://codereview.stackexchange.com/questions/137877/shell-script-wrapper-for-docker-build-and-run
% - https://github.com/JonathonReinhart/scuba -> Simple Container-Utilizing Build Apparatus
% - https://blog.codeship.com/cross-platform-docker-development-environment/
% - stack
%  - https://docs.docker.com/docker-cloud/apps/stacks/
%  - https://blog.nimbleci.com/2016/09/14/docker-stacks-and-why-we-need-them/
%  - https://blog.couchbase.com/2016/july/docker-services-stack-distributed-application-bundle
\section{Häufig benötigte Docker-Kommandos}
\label{docker-kommandos}
% - http://jimhoskins.com/2013/07/27/remove-untagged-docker-images.html
% - Scripting
% - https://rominirani.com/docker-management-commands-e89a23c55908#.wlq1ixs5i

% docker build
% docker run --rm -it -v -p
% docker rmi (cleanup)
% new docker command line
