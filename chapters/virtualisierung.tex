\chapter{Virtualisierung}
\label{cha:virtualisierung}
Die Virtualisierung von IT-Systemen entwickelte sich in den letzten Jahren zur Standardlösung bei dem Betrieb von Server-Software, doch 2016 stagnierte der Erwerb von neuen Virtualisierungslizenzen zum ersten Mal. \autocite{Gartner-Magic-Quadrant2016:online}
Zur Virtualisierung führte die Tatsache, dass leistungsfähigere Systeme, schnellere Technologiewechsel und sich ständig ändernde Voraussetzungen durch die Verwendung von rein hardwarebasierten Systemen zu teuer geworden ist.~\autocite{vmware-virtualization-history:online}

Warum Containertechnologien der nächste Schritt sind, welche Rolle Docker darin einnimmt und wohin diese Technologie noch führen kann, wird in diesem Kapitel erläutert.
\section{Beweggründe und Geschichte}
\label{sec:virtualisierungsgeschichte}
(VMWARE + PAPER + IBM) In den 1960er-Jahren begann IBM mit dem Einsatz von Großrechnern, sogenannten Mainframes.
Da die Kosten für derartige Computersysteme den Einsatz eines einzelnen Rechners nicht gerechtfertigen konnten, wurden auf einem Mainframe mehrere Systeme parallel virtuell betrieben.
Dadurch konnte die Rechnenleistung effizienter ausgenutzt werden, sowie Versionsinkompatibiläteten durch den parallelen Betrieb alter und neuer Mainframes vermieden werden.
Als im Laufe der 80er-Jahre die x86-Architektur den Aufschwung erlebte stand die Virtualisierung still.
Der günstige Preis und die fehlende Virtualisierungsunterstützung machten es unnötig und unmöglich Endgeräte zu virtualisieren.
Erst mit der wieder steigenden Rechenleistung und des Erscheinens von Mehrkernprozessoren hat die IT-Virtualisierung wieder an Traktion gewonnen.
In den letzten Jahren wird besonders durch die Cloud-Angebote alles Mögliche nur mehr virtuell betrieben.
Von der  kompletten Netzwerkinfrastruktur, bis hin zum Speicher wird in modernen Rechnezentren (Amazon, Microsoft, \dots) alles virtualisiert.
Die Analyse-Firma Gartner Inc.\ spricht von einem Virtualisierungsgrad von 75\% im Serverbereich \autocite{Gartner-Server-Virtualization:online}.
Aspekte wie die einfache Provisionierung von virtualisierten Systemen führen dazu, dass beispielsweise horizontale Skalierung ohne großen Mehraufwand betrieben werden kann.
Auch das Testen von Infrastrukturen wurde durch Virtualisierung ermöglicht.
Es ist nicht mehr notwendig ein gesamtes IT-System temporär dem Testen zur Verfügung zu stellen, oder sogar ein solches eigenes anzuschaffen, stattdessen können die benötigten Ressourcen in der Cloud lediglich für den benötigten Zeitraum angemietet werden.
% - IBM als Beginn der Virtualisierung (kurze Erklärung der Geschichte)
% - Warum wird heutzutage virtualisiert (Cloud-Umgebungen, Skalierung, Ressourcenverteilung) + Gartner-Trends
\subsubsection{Vorteile der Virtualisierung \autocite[198]{Baun2009}}
Der kostensparendste Aspekt der Virtualisierung ist die Konsolidierung von Servern.
Server, die nicht unter voller Last laufen, benötigen trotzdem Strom, Kühlung, Wartung und Infrastruktur.
Durch Konsolidierung können nun ungenutzte Ressourcen genutzt werden, die zuvor lediglich Kostern verursachten.
Virtualisierte Server bieten sind außerdem erheblich einfacher zu provisionieren.
Wird ein neuer Server benötigt, können dazu bestehende, freie Ressourcen genützt werden, anstatt, dass weitere Hardware anzuschaffen ist.

Wartungsaufgaben werden stark vereinfacht, da durch diverse Managementwerkzeuge viele Aufgaben automatisiert, sowie ohne einer Änderung an den physischen Systemen durchgeführt werden können.
Dazu zählt auch die Live-Migration von virtuellen Maschinen.
Diese können dadurch für den Endanwender unterbrechungsfrei und daher unbemerkt zwischen zwei Rechnern verschoben werden.
So wird Wartung an der Hardware ermöglicht, ohne dass sich eine Downtime für die Benutzer ergibt, Voraussetzung dafür ist allerdings, dass Ressourcen im Rechenzentrum frei sind, auf die Systeme (temporär) migriert werden können.

Durch Virtualisierung wird auch die Dimensionierung der Ressourcen erheblich vereinfacht, da lediglich eine ungefähre Menge an Rechenleistung initial zu schätzen ist, diese sich allerdings im Betrieb umverteilen lässt.
So können Systeme, die ihre Leistungsgrenzen erreicht haben, oder bei weitem nicht nützen im laufenden Betrieb neu dimensioniert werden.
Dazu kommt die vorhin beschriebene Live-Migration zum Einsatz.
Laut \autocite{Hantelmann2008} können die Rechenzentrumskosten um 50\% reduziert werden, wohingegen die Anschaffungskosten neuer Hardware um bis zu 70\% verringert werden können.
\autocite{Azure-Scaling:online} beschreibt Möglichkeiten zur automatischen Skalierung von Ressourcen in der Microsoft-Azure-Cloud.
Dabei spielt Virtualisierung eine essentielle Rolle, da alle bei Azure gemieteten Ressourcen virtualisiert laufen.
So kann in diesem Fall allerdings eine, für den Systemadministrator, angenehme Version der Dimensionierung erreicht werden, da die Azure-Cloud automatisch die Leistung der Ressourcen an die aktuelle Auslastung anpasst.

Nicht nur durch Features wie die Live-Migration wird die Flexibilität in virtualisierten Rechenzentren erhöht.
Virtuelle Maschinen bestehen aus wenigen Dateien, von denen sehr einfach Klone zum Backup erstellt werden können.
Zusätzlich gibt es die Funktion von Snapshots, dabei wird ein Abbild einer virtuellen Maschine erstellt, das jederzeit wieder hergestellt werden kann.
Dies ist besonders hilfreich, wenn es Snapshots von fertig konfigurierten, jedoch unbenutzten Systemen gibt, da damit fehlerhafte Maschinen sehr schnell wieder hergestellt werden können.

Durch die Abschottung der virtuellen Maschinen gegeneinander können trotz der Virtualisierung hohe Service Level Agreements erreicht werden, da der Ausfall einer Maschine lediglich diese betrifft, das Hostsystem bleibt allerdings intakt.
In einem Hochverfügbarkeitsszenario besteht auch die Möglichkeit, dass ein überwachendes System (Supervisor) den Ausfall erkennt und solch ein System auf einem anderen Knoten neu startet.

\subsubsection{Nachteile der Virtualisierung \autocite[198]{Baun2009}}
Da bei virtualisierten Systemen die Instruktionen auf vom virtuellen auf das Hostsystem umgesetzt werden müssen, ergibt sich ein Leistungsverlust.
Dieser wird allerdings mit leistungsfähigeren Mehrkernprozessoren und durch Prozesservirtualisierung wie Intel® VT\footnote{http://www.intel.de/content/www/de/de/virtualization/virtualization-technology/intel-virtualization-technology.html} verschwindend gering.
Die Prozessoren bieten native Virtualisierungstechniken an, bei denen die Befehle nicht mehr umgesetzt werden müssen, wodurch die Verringerung der Leistung auf unter 10\% \autocite{Hardt2005} sinkt.

Ein wesentlich größeres Problem in der Virtualisierung stellen besondere Hardwareanforderungen dar.
Authentifizierung über Hardware-Dongles oder die Ansteuerung von Legacy-Hardware ist in virtualisierten Umgebungen durch den fehlenden Direktzugriff auf die Hardware sehr schwierig bis nicht möglich.

Besondere Vorsicht muss außerdem der Infrastruktur in den Rechenzentren zukommen, da bei einem Hostausfall in virtualisierten Umgebungen zahlreiche Systeme betroffen sind.
Dieses Problem lässt sich durch redundante Installationen und gut durchdachte Ausfallkonzepte lösen, wobei hier die Vermeidung eines \emph{Single Point of Failures} (SPOF) höchste Priorität genießen muss.
Damit ein redundantes System im Fehlerfall Wirkung zeigen kann, muss dieses vollredundant sein.
Die Konzeption, Installation und der Betrieb eines solchen Systems erfordern eine hochwertige Infrastruktur und zusäzliches Detailwissen.


\section{Vollständige Virtualisierung}
\label{sec:vollständige-virtualisierung}
\autocite{Baun2009} stellt dar, dass die vollständige Virtualisierung Gastsystemen eine gesamte virtuelle Umgebung zur Verfügung stellt.
Weiters wird darin das Zusammenspiel der einzelnen Komponenten folgendermaßen beschrieben.
Der \emph{Virtuelle Maschinenmonitor} (VMM) läuft auf dem Host-System und ist jene Komponente, die die virtuelle Umgebung zur Verfügung stellt.
Dieses vollwertige System beinhaltet ein BIOS, sowie eine Abstraktion der gesamten Hardware, wodurch die Gast-Systeme nicht merken, dass sie virtualisiert werden.
Zugriffe auf die Hardware werden vom VMM intelligent auf die Hardware des Hosts verteilt, oder über Hardware-Emulation zugänglich gemacht.
Dieser Aufbau ist in \cref{fig:architektur-vollständige-virtualisierung} zu sehen.
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth,clip]{images/vollständige-virtualisierung}
    \caption{Architektur der vollständigen Virtualisierung}
\label{fig:architektur-vollständige-virtualisierung}
\end{figure}
Einerseits zeigt die Abbildung, dass Anwendungen ohne Problem parallel zu den virtualisierten Systemen laufen können, andererseits wird verdeutlicht, dass jedes virtuelle System ein gesamtes Betriebssystem (Gast-OS) beinhaltet.
Jegliche Kommunikation eines Gastsystems mit den Systemresourcen des Hosts läuft über den VMM, wodurch gewährleistet wird, dass dieser Zugriff kontrolliert werden kann.
Dies stellt sicher, dass die virtuellen Maschinen voneinander abgeschottet sind und ein Ausfall eines Gastsystems die anderen nicht beeinflusst.

Aus dieser hohen Abstraktion folgt, dass am Gastsystem keine Änderungen durchgeführt werden müssen und unterschiedliche Kernels parallel virtualisiert werden können.
Lediglich die Prozessorarchitektur muss zusammenpassen.
Der Vorteil eines gesamten Betriebssystems pro Gastsystem bringt allerdings den Nachteil mit sich, dass jedes dieser Systeme Speicher für den Kernel und das Betriebssystem belegt. Weiters ist ein Bootvorgang nötig, der die Verwendung zu Entwicklungszwecken verzögert.
Allerdings gibt die vollständige Virtualisierung dem Entwickler die Möglichkeit, seine Software auf dem lokalen Rechner auf verschiedenen Betriebssystemen zu testen, oder Werkzeuge zu verwenden, die auf dem Host-System nicht verfügbar sind.
Außerdem können vorgefertigte \emph{Basissysteme} (Snapshots) für die Entwickler bereitgestellt werden, um die Konfigurationszeit zu verkürzen und eine einheitliche Entwicklungsumgebung zu haben.
Folgende Probleme treten hingegen in einer virtualisierten Entwicklungsumgebung auf:
\begin{itemize}
\item Updates müssen nun entweder doppelt durchgeführt werden, oder die Entwickler werden periodisch mit neuen Snapshots versorgt.
\item Für die Daten und Konfigurationen der Entwickler muss ein Platz außerhalb der virtuellen Maschine gefunden werden. Besonders bei einem Snapshot-basierten Updateverfahren gehen durch die Verwendung eines neuen Snapshots alle Daten in der VM verloren. Die Konfiguration der Entwicklungsumgebung können idealerweise auf Netzwerklaufwerke verlegt werden und die Quelltexte sollten sich in einem Versionskontrollsystem befinden.
\item Ein weiters Problem mit den Daten betrifft die Authentifizierung. Für SSH-Schlüssel für Versionskontrollsysteme und andere Zugangsdaten muss ebenfalls eine Möglichkeit geschaffen werden, diese in die virtuellen Maschinen zu bringen. 
\item Entwicklungsumgebungen gelangen bei virtualisierten System schnell an die Performancegrenzen, wodurch die Produktivität der Mitarbeiter sinkt.
\item Bei mehreren parallelen Projekten und damit verbundenen virtuellen Maschinen kann der Speicherplatz auf dem Host-System sehr knapp werden.
\end{itemize}
Wie sich die vollständige Virtualisierung für Entwickler in der Praxis verwenden lässt, wird in \cref{sub:vagrant} dargestellt.  

Gartner Servervirtualisierung
% - Abgrenzung zu Hardwarevirtualisierung + Warum sinnvoll?
% - kurz das Rechtekonzept mit den Ringen erklären
% - Vor- \& Nachteile bei Servervirtualisierung
%   - Speicherplatz
%   - ganzes System kann, aber muss abstrahiert werden (Kernel, ...)
% - http://winfwiki.wi-fom.de/index.php/Entwicklung,_aktueller_Stand_und_Zukunft_von_Virtualisierungsl%C3%B6sungen_im_Serverbereich#cite_note-0
% - http://www.gartner.com/newsroom/id/3315817
% - https://www.gartner.com/doc/reprints?ct=160707&id=1-3B9FAM0&st=sb
\section{Containervirtualisierung}
\label{sec:containervirtualisierung}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\linewidth,clip]{images/vollständige-virtualisierung}
    \caption{Architektur der vollständigen Virtualisierung}
\label{fig:architektur-vollständige-virtualisierung}
\end{figure}
% - https://semaphoreci.com/community/tutorials/how-to-deploy-a-go-web-application-with-docker
% - Grafik der Containervirtualisierung, Shared Host with mapped Syscalls
% - Abschottung/Security
% - Produkte (https://coreos.com/rkt/docs/latest/rkt-vs-other-projects.html)
\begin{description}
    \item [Docker] \blindtext
    \item [rkt] \blindtext
    \item [containerd] \blindtext
    \item [LXC/LXD] \blindtext
    \item [OpenVZ] \blindtext
\end{description}
% - file:///D:/download/Realitaetscheck-Brauchen-wir-Docker-wirklich_Nils-Magnus_inovex-GmbH.pdf
\subsection{Open Container Initiative (\emph{OCI})}
\label{sec:open-container-initiative}
\subsection{Orchestrierungsmechanismen}
\label{sec:orchestrierungsmechanismen}
% - DC/OS
% - Mesosphere
% - Swarm
% - Kubernetes
% - https://www.sigs-datacom.de/uploads/tx_dmjournals/rossbach_OTS_Architekturen_15.pdf !!!
% - https://www.google.at/search?q=container+orchestration&ie=&oe=
% - http://stackoverflow.com/questions/29198840/marathon-vs-kubernetes-vs-docker-swarm-on-dc-os-with-docker-containers
